{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-55200a77-f0e6-4ed5-95fe-795d97af30fa",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Taller II: Implementing a simple ASR system using HMM\n",
    "\n",
    "En este taller implementaremos un sistema de reconocimiento automatico de habla, utilizando modelos ocultos de markov. Para este taller se puede utilizar la libreria [hmmlearn](https://hmmlearn.readthedocs.io/en/latest/tutorial.html#customizing) de Python. Este taller será parte de la nota del proyecto de evaluación del primer corte. Así que se deberá entregar al finalizar la semana 5 junto con el desarrollo del proyecto de evaluación.\n",
    "\n",
    "En este taller implementaremos un sistema de reconocimiento de habla de palabras aisladas. Esto quiere decir que hay una separación entre cada palabra pronunciada, y no se utilizará  habla fluida continua. La idea es implementar un sistema sencillo con un vocabulario limitado, para qu epuedan entender el principio de funcionamiento de estos sistemas. Para este taller deben seguir lso siguientes pasos:\n",
    "\n",
    "1. Cree un diccionaro pequeño compuesto de alrededor de 20 palabras. Si desean incluir más palabras no hay problema.\n",
    "2. Cada una de estas palabras dividalas en fonemas. Asigne a cada fonema un número para facilitar su identificación.\n",
    "3. Grabé cada una de las palbaras de forma aislada. \n",
    "4. Para cada señal de voz grabada calcule el mel espectrograma utilizando 39 componentes (este es el estandar que usan los sistemas modernos).\n",
    "5. Identifique las secciones del mel spectrograma que corresponden a cada fonema.\n",
    "6. Modele la distribución de los vectores del Mel espectrograma para cada fonema, esto puede hacerlo usando GMM (Gaussian Mixture Models).\n",
    "7. Calcule la matrix de probabilidades de transición utilizando el diccionario que ustedes crearón.\n",
    "8. Implemente el modelo HMM.\n",
    "9. Pruebe con los datos de entrenamiento si el modelo produce la secuencia de fonemas indicada.\n",
    "10. Genere un nuevo conjunto de palabras (al menos 10) que se conformen con los fonemas presentes en su diccionario. A partir de la señal de voz de cada una de estas nuevas palabras, trate de predecir la palbara escrita utilizando el modelo implementado.\n",
    "\n",
    "**NOTA:** Trate de Utilizar fonemas que tengan una única relación con letras (silabas) del alfabeto. Esto disminuirá la tasa de error del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-5e783185-43b6-4edd-b7dd-39d2ba2cad0b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-5fc99bb1-beeb-4fd9-adf5-4ef2b974283f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Sergio Nicolás Duque Báez \n",
    "#### Víctor Samuel Pérez Díaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas librerias fueron importadas en python 3.8.5. En 3.9 hay problemas.\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from librosa import mel_frequencies\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.display import specshow\n",
    "from scipy.io.wavfile import write\n",
    "from scipy import signal as sig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-ba1e1730-0b16-43fc-aa81-1bf38c31e8a2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-74952c33-5a25-48f4-bfe1-2172f07a2a5c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1614113434910,
    "source_hash": "51f0857f"
   },
   "outputs": [],
   "source": [
    "dic = ['aspa', 'abeja', 'mama', 'mapa', 'avispa', 'oveja', 'beso', 'peso', 'pata', 'cabo', 'capo', 'escarbar', 'escapar', 'borra', \n",
    "'gorra', 'ancla', 'vista', 'pista', 'papa', 'pasta', 'grama', 'bomba']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-9de34e5d-f882-4189-b0d8-b2b6e41ff067",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-cd03f848-013e-4049-8333-a974673f6fcb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1614120365334,
    "source_hash": "4b6d40c0"
   },
   "outputs": [],
   "source": [
    "phonems = ['a', 's', 'p', 'b', 'e', 'j', 'm', 'v', 'i', 'o', 'v', 't', 'c', 'r', 'rr', 'g', 'n', 'l']\n",
    "\n",
    "phonems.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## JUST RUN FOR RECORDING ##############\n",
    "############## JUST RUN FOR RECORDING ##############\n",
    "############## JUST RUN FOR RECORDING ##############\n",
    "############## IR AL SIGUIENTE PASO   ##############\n",
    "\n",
    "# Setting the interfaz to acquire de audio data\n",
    "fs = 8000  # Sample rate\n",
    "seconds = 2  # Duration of recording\n",
    "\n",
    "n=1\n",
    "for word in dic:\n",
    "    \n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "\n",
    "    # Acquiring audio data\n",
    "    print('Start speaking: ' + 'audios/{}_{}.wav'.format(word, n))\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print('End of Recording.')\n",
    "    \n",
    "    write('audios/{}_{}.wav'.format(word, n), fs, myrecording)  # Save as WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting audio\n",
    "\n",
    "y, fs = sf.read('audios/aspa_0.wav')\n",
    "y = y/np.std(y)\n",
    "sd.play(y, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Mel-Spectrogram\n",
    "n_coeff = 39\n",
    "\n",
    "Sm = melspectrogram(y=y, sr=fs, window = window, win_length = 160, n_fft=nfft, hop_length=len_over, n_mels = n_coeff)\n",
    "fm = mel_frequencies(n_mels=n_coeff, fmin=20, fmax=fs/2, htk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,12))\n",
    "plt.plot(y);\n",
    "plt.title('Signal');\n",
    "plt.xlabel('Time (samples)');\n",
    "plt.ylabel('Amplitude');"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "184dc3fa-5b94-402f-8e17-896580635461",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
