{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-55200a77-f0e6-4ed5-95fe-795d97af30fa",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Taller II: Implementing a simple ASR system using HMM\n",
    "\n",
    "En este taller implementaremos un sistema de reconocimiento automatico de habla, utilizando modelos ocultos de markov. Para este taller se puede utilizar la libreria [hmmlearn](https://hmmlearn.readthedocs.io/en/latest/tutorial.html#customizing) de Python. Este taller será parte de la nota del proyecto de evaluación del primer corte. Así que se deberá entregar al finalizar la semana 5 junto con el desarrollo del proyecto de evaluación.\n",
    "\n",
    "En este taller implementaremos un sistema de reconocimiento de habla de palabras aisladas. Esto quiere decir que hay una separación entre cada palabra pronunciada, y no se utilizará  habla fluida continua. La idea es implementar un sistema sencillo con un vocabulario limitado, para qu epuedan entender el principio de funcionamiento de estos sistemas. Para este taller deben seguir lso siguientes pasos:\n",
    "\n",
    "1. Cree un diccionaro pequeño compuesto de alrededor de 20 palabras. Si desean incluir más palabras no hay problema.\n",
    "2. Cada una de estas palabras dividalas en fonemas. Asigne a cada fonema un número para facilitar su identificación.\n",
    "3. Grabé cada una de las palbaras de forma aislada. \n",
    "4. Para cada señal de voz grabada calcule el mel espectrograma utilizando 39 componentes (este es el estandar que usan los sistemas modernos).\n",
    "5. Identifique las secciones del mel spectrograma que corresponden a cada fonema.\n",
    "6. Modele la distribución de los vectores del Mel espectrograma para cada fonema, esto puede hacerlo usando GMM (Gaussian Mixture Models).\n",
    "7. Calcule la matrix de probabilidades de transición utilizando el diccionario que ustedes crearón.\n",
    "8. Implemente el modelo HMM.\n",
    "9. Pruebe con los datos de entrenamiento si el modelo produce la secuencia de fonemas indicada.\n",
    "10. Genere un nuevo conjunto de palabras (al menos 10) que se conformen con los fonemas presentes en su diccionario. A partir de la señal de voz de cada una de estas nuevas palabras, trate de predecir la palbara escrita utilizando el modelo implementado.\n",
    "\n",
    "**NOTA:** Trate de Utilizar fonemas que tengan una única relación con letras (silabas) del alfabeto. Esto disminuirá la tasa de error del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-5e783185-43b6-4edd-b7dd-39d2ba2cad0b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-5fc99bb1-beeb-4fd9-adf5-4ef2b974283f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Sergio Nicolás Duque Báez \n",
    "#### Víctor Samuel Pérez Díaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas librerias fueron importadas en python 3.8.5. En 3.9 hay problemas.\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from itertools import islice\n",
    "from librosa import mel_frequencies\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.display import specshow\n",
    "from scipy.io.wavfile import write\n",
    "from scipy import signal as sig\n",
    "from scipy import ndimage as nd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############## JUST RUN FOR RECORDING ##############\n",
    "############## JUST RUN FOR RECORDING ##############\n",
    "############## JUST RUN FOR RECORDING ##############\n",
    "############## IR AL SIGUIENTE PASO   ##############\n",
    "\n",
    "# Setting the interfaz to acquire de audio data\n",
    "fs = 8000  # Sample rate\n",
    "seconds = 2  # Duration of recording\n",
    "\n",
    "n=1\n",
    "for word in dic:\n",
    "    \n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "\n",
    "    # Acquiring audio data\n",
    "    print('Start speaking: ' + 'audios/{}_{}.wav'.format(word, n))\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print('End of Recording.')\n",
    "    \n",
    "    write('audios/{}_{}.wav'.format(word, n), fs, myrecording)  # Save as WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00005-74952c33-5a25-48f4-bfe1-2172f07a2a5c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1614113434910,
    "source_hash": "51f0857f"
   },
   "outputs": [],
   "source": [
    "dic = ['aspa', 'abeja', 'mama', 'mapa', 'avispa', 'oveja', 'beso', 'peso', 'pata', 'cabo', 'capo', 'escarbar', 'escapar', \n",
    "       'borra', 'gorra', 'ancla', 'vista', 'pista', 'papa', 'pasta', 'grama', 'bomba']\n",
    "\n",
    "dic_phonems = {'aspa': ['a', 's', 'p', 'a'], 'abeja': ['a', 'b', 'e', 'j', 'a'], 'mama': ['m', 'a', 'm', 'a'], \n",
    "               'mapa': ['m', 'a', 'p', 'a'], 'avispa': ['a', 'v', 'i', 's', 'p', 'a'], 'oveja': ['o', 'v','e', 'j', 'a'], \n",
    "               'beso': ['b', 'e', 's', 'o'], 'peso': ['p', 'e', 's', 'o'], 'pata': ['p', 'a', 't', 'a'], \n",
    "               'cabo': ['c', 'a', 'b', 'o'], 'capo': ['c', 'a', 'p', 'o'], 'escarbar': ['e', 's', 'c', 'a', 'r', 'b', 'a', 'r'], 'escapar': ['e', 's', 'c', 'a', 'p', 'a', 'r'], 'borra': ['b', 'o', 'rr', 'a'], \n",
    "               'gorra': ['g', 'o', 'rr', 'a'] , 'ancla': ['a', 'n', 'c', 'l', 'a'], 'vista': ['v', 'i', 's', 't', 'a'], \n",
    "               'pista': ['p', 'i', 's', 't', 'a'], 'papa': ['p', 'a', 'p', 'a'], 'pasta': ['p', 'a', 's', 't', 'a'], \n",
    "               'grama': ['g', 'r', 'a', 'm', 'a'], 'bomba': ['b', 'o', 'm', 'b', 'a']}\n",
    "\n",
    "phonems = ['a', 's', 'p', 'b', 'e', 'j', 'm', 'v', 'i', 'o', 't', 'c', 'r', 'rr', 'g', 'n', 'l']\n",
    "phonems.sort()\n",
    "dic_matrix = {k:[] for k in phonems}\n",
    "\n",
    "def splitmel(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out\n",
    "\n",
    "def extract_from_word(y, fs, word, dic_phonems):\n",
    "    \n",
    "    env = np.abs(sig.hilbert(y))\n",
    "    env = nd.uniform_filter1d(env, 500)\n",
    "    env_mask = env > 0.5\n",
    "    \n",
    "    y_talk = y[env_mask]\n",
    "    \n",
    "    # Computing\n",
    "    len_win = int(np.fix(0.02*fs)) # Defining the samples for a 20ms window\n",
    "    window = np.hanning(len_win) # Computing the window length to compute the spectrogram\n",
    "    len_over = int(np.fix(0.01*fs)) # Defining number of samples for an overlap of 10ms between consecutive windows\n",
    "    #nfft = 512 # Number of points for the FFT\n",
    "    \n",
    "    # Computing the Mel-Spectrogram\n",
    "    n_coeff = 39\n",
    "\n",
    "    Sm = melspectrogram(y=y[env_mask], sr=fs, window = window, win_length = len_win, hop_length=len_over, n_mels = n_coeff)\n",
    "    fm = mel_frequencies(n_mels=n_coeff, fmin=20, fmax=fs/2, htk=False)\n",
    "    \n",
    "    word_phonems = dic_phonems[word]\n",
    "    split_talk = splitmel(Sm, len(word_phonems))\n",
    "    \n",
    "    for p in range(len(word_phonems)):\n",
    "        #print(word_phonems[p])\n",
    "        dic_matrix[word_phonems[p]].append(np.average(split_talk[p])) \n",
    "        \n",
    "    return None\n",
    "\n",
    "def fill_phonems(dir, number, dic):\n",
    "    # Extracting audio\n",
    "    for i in range(len(dic)):\n",
    "        name = dic[i]\n",
    "        y, fs = sf.read('{}/{}{}.wav'.format(dir, name, number))\n",
    "        y = y/np.std(y)\n",
    "        #sd.play(y, fs)\n",
    "\n",
    "        if len(y.shape) > 1:\n",
    "            y = y[:,0]\n",
    "\n",
    "        extract_from_word(y, fs, name, dic_phonems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_phonems('audios2', '2', dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1595.8085689262502,\n",
       "  0.004407669955270669,\n",
       "  1336.3379734530877,\n",
       "  8.280689999810806e-05,\n",
       "  399.1612963340067,\n",
       "  0.00032515084197015377,\n",
       "  469.3178314769941,\n",
       "  0.0006856139747770831,\n",
       "  2507.0346243035024,\n",
       "  0.00016369027372931062,\n",
       "  0.0002486460599617333,\n",
       "  1263.024660010074,\n",
       "  0.0016474027332576593,\n",
       "  587.3919042523503,\n",
       "  1166.2162773281545,\n",
       "  46.12615575720718,\n",
       "  0.12421802471227955,\n",
       "  62.75252038282814,\n",
       "  0.12096850314117892,\n",
       "  0.0009092763734299874,\n",
       "  0.00042047145219037705,\n",
       "  1053.3228840551878,\n",
       "  0.00017536620431519512,\n",
       "  0.0016376777191796472,\n",
       "  0.0013430190236223384,\n",
       "  1219.686776340853,\n",
       "  0.0016438264232562939,\n",
       "  2615.5846180293347,\n",
       "  0.001162758205954301,\n",
       "  41.968787562303646,\n",
       "  3.21305422318894e-05,\n",
       "  3.207642198381709e-05,\n",
       "  264.5809278988427,\n",
       "  0.41926747724230845,\n",
       "  333.84841467802164,\n",
       "  0.005618967525738665,\n",
       "  6.5893815107330775,\n",
       "  0.010972055221268623,\n",
       "  28.453515952589456,\n",
       "  0.011844890216651253,\n",
       "  355.2610685281567,\n",
       "  0.7266735978008126,\n",
       "  0.010640901209199652,\n",
       "  8.224186003246707,\n",
       "  0.009077771869762786,\n",
       "  40.20664341745686,\n",
       "  19.65479035250185,\n",
       "  3.011937941455132,\n",
       "  1.115815178830513,\n",
       "  0.3025480151585604,\n",
       "  0.3219120557924316,\n",
       "  0.012961644014622827,\n",
       "  0.013233364799718947,\n",
       "  301.99373466439954,\n",
       "  0.011822093991754112,\n",
       "  1.0359836597611118,\n",
       "  1.4757771456181528,\n",
       "  7.0060354289878175,\n",
       "  0.013791942163376147,\n",
       "  56.60595544729429,\n",
       "  0.0575967586834472,\n",
       "  5.106507448061126,\n",
       "  0.008315795789680868,\n",
       "  0.00504340928248932],\n",
       " 'b': [830.5752847157218,\n",
       "  2325.3428504871663,\n",
       "  2.142933136707345,\n",
       "  1.0875747905710738,\n",
       "  2237.320452964095,\n",
       "  2874.83247723939,\n",
       "  0.015946926411281984,\n",
       "  15.087449540237955,\n",
       "  257.16458203003987,\n",
       "  0.2575924461188266,\n",
       "  0.4278495138428017,\n",
       "  379.9340096768629,\n",
       "  379.12327524832193,\n",
       "  0.022084355479561914],\n",
       " 'c': [1271.838785926813,\n",
       "  1431.7284049982516,\n",
       "  111.71291433377786,\n",
       "  212.9503699739622,\n",
       "  62.759981196458135,\n",
       "  345.7626388243482,\n",
       "  279.76689599383474,\n",
       "  19.494415356090283,\n",
       "  16.800141408578355,\n",
       "  0.7337332240706359],\n",
       " 'e': [54.44130932452809,\n",
       "  23.58648373764346,\n",
       "  37.898056908446236,\n",
       "  36.86249592650168,\n",
       "  2294.017415960282,\n",
       "  2630.9905649155876,\n",
       "  0.5165546165762133,\n",
       "  2.7297347942930723,\n",
       "  0.8404585925144983,\n",
       "  1.817424079053425,\n",
       "  512.5304543365633,\n",
       "  399.52462592223867],\n",
       " 'g': [2083.4743654992053,\n",
       "  2119.1723226857384,\n",
       "  276.79448107760044,\n",
       "  329.29813512406344],\n",
       " 'i': [214.188519878616,\n",
       "  40.517180937526504,\n",
       "  46.49753046798229,\n",
       "  5.244827623326451,\n",
       "  0.5240943570781139,\n",
       "  1.6469166203250956],\n",
       " 'j': [0.5652146522197136,\n",
       "  1.5830223294782393,\n",
       "  0.02188145264245424,\n",
       "  0.028823487437127763],\n",
       " 'l': [2.154512075985522, 0.044127242612030534],\n",
       " 'm': [1587.14123082982,\n",
       "  1.1393250944976507,\n",
       "  2230.3452066216505,\n",
       "  0.22212010658885878,\n",
       "  0.33321330489517637,\n",
       "  256.3869602061314,\n",
       "  0.06524023974893678,\n",
       "  279.80308616479726,\n",
       "  0.027489714602552083,\n",
       "  0.11037620209423875],\n",
       " 'n': [1785.2185545066652, 17.50717796601672],\n",
       " 'o': [2623.8393312218127,\n",
       "  0.012420312060362412,\n",
       "  0.032753882355117614,\n",
       "  0.0015781652614441043,\n",
       "  0.001814614904383028,\n",
       "  80.59415923023776,\n",
       "  252.35568968174528,\n",
       "  98.77233959114616,\n",
       "  417.6748373858807,\n",
       "  0.05297759948358348,\n",
       "  0.19261764838967022,\n",
       "  0.018830785186896525,\n",
       "  0.009523033918003567,\n",
       "  7.743422140852518,\n",
       "  14.711096905893296,\n",
       "  10.791906315518807],\n",
       " 'p': [8.77840038960222,\n",
       "  0.9623947967314782,\n",
       "  0.4895434972524631,\n",
       "  3441.5447999032467,\n",
       "  1472.0933883021098,\n",
       "  3.176637487144922,\n",
       "  6.7957828707183925,\n",
       "  3874.241947528238,\n",
       "  2165.0894384380076,\n",
       "  3.008088312346933,\n",
       "  1404.1646762135665,\n",
       "  0.5192705798629969,\n",
       "  0.20452890711603855,\n",
       "  2.7283076614806347,\n",
       "  255.6486045522736,\n",
       "  297.93117933048575,\n",
       "  0.11447996240928929,\n",
       "  0.03655415146244753,\n",
       "  310.37249864078404,\n",
       "  275.6188172118267,\n",
       "  0.11268999506572375,\n",
       "  309.1612121485807],\n",
       " 'r': [14.926994683537888,\n",
       "  5.214472375872117e-05,\n",
       "  0.00025294484570269777,\n",
       "  517.2082334353142,\n",
       "  0.2275608439701779,\n",
       "  0.016419163667009188,\n",
       "  0.009297282114301203,\n",
       "  36.76948135241565],\n",
       " 'rr': [0.14665472598401988,\n",
       "  0.42207479593604896,\n",
       "  0.05547692293480416,\n",
       "  0.19876679500624406],\n",
       " 's': [1607.8145097856034,\n",
       "  9.483886681220385,\n",
       "  12.172036481312462,\n",
       "  7.033086420512848,\n",
       "  959.4457756156868,\n",
       "  983.3394200799023,\n",
       "  15.092508113819255,\n",
       "  19.862166137329048,\n",
       "  74.50611157527987,\n",
       "  24.73468686913836,\n",
       "  0.5628910300983311,\n",
       "  0.1362831265869088,\n",
       "  0.38641353959878605,\n",
       "  57.94897127643402,\n",
       "  50.66410486844912,\n",
       "  0.5446098668831386,\n",
       "  0.5344120152193278,\n",
       "  0.2355245428451792],\n",
       " 't': [3.7559301206301883,\n",
       "  1.4658639311663033,\n",
       "  2.073061417926046,\n",
       "  2.208701788097118,\n",
       "  0.06750238215364926,\n",
       "  4.157469571179334,\n",
       "  3.369798527114526,\n",
       "  0.5350429007982913],\n",
       " 'v': [583.6384965625824,\n",
       "  110.47054400987011,\n",
       "  3239.969832457569,\n",
       "  33.01939007616784,\n",
       "  12.3858573300328,\n",
       "  331.2184318708305]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_phon = []\n",
    "for p in phonems:\n",
    "    phon = np.array(dic_matrix[p]).reshape(-1, 1)\n",
    "    gm = GaussianMixture(n_components=2, random_state=0).fit(phon)\n",
    "    gm_phon.append(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n=2):\n",
    "    \"Sliding window width n from seq.  From old itertools recipes.\"\"\"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs= pd.DataFrame()  \n",
    "for w in dic:\n",
    "    pairs_i = pd.DataFrame(window(dic_phonems[w]), columns=['state1', 'state2'])\n",
    "    pairs = pd.concat([pairs,pairs_i])\n",
    "    \n",
    "counts = pairs.groupby('state1')['state2'].value_counts() #+ counts\n",
    "probs = (counts / counts.sum()).unstack()\n",
    "probs = probs.fillna(0)\n",
    "g = np.zeros(len(probs))\n",
    "probs.insert(4, 'g', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_freqs =  Counter()\n",
    "for w in dic:\n",
    "    for i in range(len(dic_phonems[w])):\n",
    "        counts_freqs.update([dic_phonems[w][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "startprob = np.array(list(counts_freqs.values()))/sum(counts_freqs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.GMMHMM(n_components=17, covariance_type=\"full\")\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = probs.to_numpy()\n",
    "model.weights_ = np.array([x.weights_ for x in gm_phon])\n",
    "model.means_ = np.array([x.means_ for x in gm_phon])\n",
    "model.covars_ = np.array([x.covariances_ for x in gm_phon])[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rows of transmat_ must sum to 1.0 (got [0.19277108 0.08433735 0.06024096 0.07228916 0.02409639 0.03614458\n 0.02409639 0.01204819 0.06024096 0.01204819 0.04819277 0.13253012\n 0.02409639 0.02409639 0.10843373 0.04819277 0.03614458])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-421393d769d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\hmmlearn\\base.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \"\"\"\n\u001b[0;32m    415\u001b[0m         \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"startprob_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\hmmlearn\\hmm.py\u001b[0m in \u001b[0;36m_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\hmmlearn\\base.py\u001b[0m in \u001b[0;36m_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \"transmat_ must have shape (n_components, n_components)\")\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransmat_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m             raise ValueError(\"rows of transmat_ must sum to 1.0 (got {})\"\n\u001b[0m\u001b[0;32m    601\u001b[0m                              .format(self.transmat_.sum(axis=1)))\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: rows of transmat_ must sum to 1.0 (got [0.19277108 0.08433735 0.06024096 0.07228916 0.02409639 0.03614458\n 0.02409639 0.01204819 0.06024096 0.01204819 0.04819277 0.13253012\n 0.02409639 0.02409639 0.10843373 0.04819277 0.03614458])"
     ]
    }
   ],
   "source": [
    "X, Z = model.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([0.19277108,0.08433735,0.06024096, 0.07228916, 0.02409639, 0.03614458, 0.02409639,\n",
    "        0.01204819, 0.06024096, 0.01204819, 0.04819277, 0.13253012,\n",
    " 0.02409639, 0.02409639, 0.10843373, 0.04819277, 0.03614458])"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "184dc3fa-5b94-402f-8e17-896580635461",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
